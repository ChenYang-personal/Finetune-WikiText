{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d848f88",
   "metadata": {},
   "source": [
    "# Fine‑Tuning DistilGPT2 on WikiText‑2 for Domain Adaptation\n",
    "\n",
    "**Author:** Chen Yang  \n",
    "**NUID:** 002837912\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The rapid evolution of large language models (LLMs) over the past several years has profoundly impacted the field of natural language processing (NLP). Models such as GPT, BERT, and their distilled variants like DistilGPT2 have set new benchmarks in tasks ranging from text generation and summarization to translation and question answering. These pre‑trained transformers leverage massive corpora of diverse, mostly general‑domain text, which gives them broad language understanding but sometimes leaves them under‑optimized for specialized or niche domains. Fine‑tuning—further training a pre‑trained model on domain‑specific data—bridges this gap by allowing the model to adapt its internal representations to the unique vocabulary, style, and semantic patterns of a target dataset.\n",
    "\n",
    "In this notebook, we demonstrate the end‑to‑end workflow for adapting DistilGPT2, a lightweight and efficient variant of GPT2, to a small subset of the WikiText‑2 corpus. Our goal is to show how domain partitioning, tokenization, training configuration, and evaluation metrics come together to yield measurable improvements. We begin by loading the raw WikiText‑2 dataset and performing a simple filtering step to remove empty or whitespace‑only lines. This ensures that each training example contains actual text. To keep runtimes manageable on modest hardware (e.g., a single GPU), we then select the first 2,000 non‑empty lines for training and 500 lines for validation.\n",
    "\n",
    "Next, we tokenize the filtered text using the DistilGPT2 tokenizer, adding special end‑of‑text tokens and padding where necessary. We group tokens into fixed‑length blocks (128 tokens each), which is a common practice for causal language models. This block grouping ensures that each training example represents a continuous chunk of natural text, enabling our model to learn long‑range dependencies.\n",
    "\n",
    "Once preprocessing is complete, we load the pre‑trained DistilGPT2 model and evaluate its baseline performance on the validation set, computing the standard language‑modeling metric of perplexity. Perplexity measures how “surprised” the model is by the actual next tokens; lower perplexity indicates better predictive performance. We record this baseline value to quantify the impact of fine‑tuning.\n",
    "\n",
    "For the fine‑tuning step, we configure `TrainingArguments` to leverage GPU acceleration and mixed‑precision (`fp16`) for faster, more memory‑efficient training. We run one epoch of training on our 2,000‑line subset, then re‑evaluate on the same validation blocks. The reduction in perplexity demonstrates the model’s improved ability to fit the domain data. To push performance further, we also include an optional hyperparameter grid search cell, exploring different learning rates, batch sizes, and epoch counts to find the configuration that yields the lowest perplexity.\n",
    "\n",
    "Throughout the notebook, we emphasize clear documentation and reproducibility: every code cell is accompanied by explanation, and all parameters are logged. By the end, readers will have a template they can adapt to any domain‑specific corpus or model family. Whether you aim to specialize an LLM for legal text, medical records, customer support transcripts, or any other domain, this notebook lays out the essential steps: dataset preparation, tokenization, baseline evaluation, fine‑tuning, post‑training evaluation, and hyperparameter optimization.\n",
    "\n",
    "Beyond perplexity, one could extend this workflow to human‑in‑the‑loop evaluation, downstream task performance (e.g., question answering accuracy), or qualitative analysis of generated samples. This exercise firmly establishes the principle that targeted fine‑tuning on in‑domain data significantly enhances an LLM’s capabilities, unlocking more reliable and context‑aware language generation for specialized applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f011fa38",
   "metadata": {},
   "source": [
    "## Installing Required Python Packages\n",
    "\n",
    "Before running the notebook, we need to install a few key libraries:\n",
    "\n",
    "```bash\n",
    "%pip install transformers datasets evaluate\n",
    "%pip install 'accelerate>=0.26.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e61bb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: evaluate in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\xsyyy\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d938117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44de2ae",
   "metadata": {},
   "source": [
    "## Explanation of the Code\n",
    "\n",
    "The provided Python code snippet is used for fine-tuning a language model using Hugging Face's Transformers library, which simplifies tasks related to natural language processing (NLP).\n",
    "\n",
    "### Imported Modules:\n",
    "\n",
    "- **math**: Python's built-in library, used primarily for numerical operations, although it is not explicitly used in the given snippet.\n",
    "- **datasets**: From Hugging Face's library, it is used for loading and managing datasets.\n",
    "- **transformers**: Provides functionalities for working with pre-trained transformer models like GPT, BERT, and others.\n",
    "\n",
    "### Key Components from `transformers`:\n",
    "\n",
    "- **AutoTokenizer**: Automatically loads the tokenizer associated with the pre-trained language model. Tokenizers convert textual data into numerical representations (tokens) that the model can understand.\n",
    "  \n",
    "- **AutoModelForCausalLM**: Automatically selects and loads a pre-trained model suitable for causal language modeling tasks. In causal language modeling, the model predicts the next token given previous tokens, commonly used in generative language models such as GPT.\n",
    "  \n",
    "- **DataCollatorForLanguageModeling**: Prepares batches of tokenized data for language modeling training. It handles padding, masking, and batching tokens efficiently.\n",
    "  \n",
    "- **Trainer**: Simplifies the training process, abstracting complex details like training loops, evaluation steps, logging, checkpoint saving, and gradient calculations.\n",
    "  \n",
    "- **TrainingArguments**: Contains settings and hyperparameters for training, such as the learning rate, number of epochs, batch size, logging intervals, and other essential configuration details.\n",
    "\n",
    "### Typical Workflow with the Imported Components:\n",
    "\n",
    "1. **Loading Dataset**:  \n",
    "   Use `load_dataset()` to load and preprocess text datasets.\n",
    "\n",
    "2. **Tokenizing Data**:  \n",
    "   Use `AutoTokenizer` to convert textual inputs into tokens.\n",
    "\n",
    "3. **Preparing Model**:  \n",
    "   Utilize `AutoModelForCausalLM` to instantiate a pre-trained model for causal language modeling.\n",
    "\n",
    "4. **Data Collation**:  \n",
    "   Employ `DataCollatorForLanguageModeling` to create training batches, applying padding or masking as necessary.\n",
    "\n",
    "5. **Training**:  \n",
    "   Configure training parameters with `TrainingArguments`, and then use the `Trainer` class to train the model efficiently.\n",
    "\n",
    "Overall, this code snippet sets up the necessary modules and components for efficiently fine-tuning a transformer-based causal language model, leveraging Hugging Face's user-friendly and powerful toolkit for NLP tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f52b218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0373c19e7e5c4013bc2d39362e76854a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feae4b5e6e60454aa8c477bbe6a0c8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \\n\"}\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 – Load & Filter a Small Dataset Subset\n",
    "raw = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "\n",
    "# Remove empty or whitespace-only lines\n",
    "train_full = raw[\"train\"].filter(lambda ex: ex[\"text\"].strip() != \"\")\n",
    "val_full   = raw[\"validation\"].filter(lambda ex: ex[\"text\"].strip() != \"\")\n",
    "\n",
    "# Now take a tiny subset for speed\n",
    "train_raw = train_full.select(range(2000))     # first 2,000 non-empty lines\n",
    "val_raw   = val_full.select(range(500))        # first 500 non-empty lines\n",
    "\n",
    "# Quick sanity check\n",
    "print(train_raw[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da54fd7f",
   "metadata": {},
   "source": [
    "## Explanation of the Code – Loading and Filtering a Dataset Subset\n",
    "\n",
    "This Python code snippet demonstrates how to efficiently load, filter, and prepare a small subset of textual data from the WikiText-2 dataset, commonly used in language modeling tasks. First, the dataset named **\"wikitext-2-raw-v1\"** is loaded from Hugging Face's `datasets` library. This dataset contains raw Wikipedia articles suitable for training and evaluating language models.\n",
    "\n",
    "After loading, the dataset typically includes empty or whitespace-only lines, which do not provide meaningful training information. The code applies filtering to remove these unnecessary entries, keeping only lines containing actual textual content. This step ensures cleaner data, improving model quality and training efficiency.\n",
    "\n",
    "To facilitate faster experimentation, especially beneficial when testing and debugging models, the code selects a significantly smaller portion from both the training and validation sets. Specifically, it retains only the first 2,000 non-empty lines from the training set and 500 non-empty lines from the validation set. Reducing the dataset size in this manner accelerates training iterations, allowing quicker feedback during development.\n",
    "\n",
    "Finally, a quick check is performed by printing an example from the training subset. This sanity check helps confirm the data has been correctly loaded, filtered, and subsetted, ensuring readiness for subsequent modeling tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c55c0e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "# Ensure the tokenizer adds a pad token (GPT2 has none by default)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_batch(examples):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "    \n",
    "train_tok = train_raw.map(tokenize_batch, batched=True, remove_columns=[\"text\"])\n",
    "val_tok   = val_raw.map(tokenize_batch, batched=True, remove_columns=[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccdddd1",
   "metadata": {},
   "source": [
    "## Explanation of the Code – Tokenizing the Dataset\n",
    "\n",
    "This Python snippet demonstrates tokenizing text data in preparation for language model training. It utilizes Hugging Face's Transformers library to convert raw textual data into numerical tokens suitable for input into a pre-trained language model.\n",
    "\n",
    "Firstly, the tokenizer for the **\"distilgpt2\"** model—a distilled, smaller variant of GPT-2—is loaded. Since GPT-2's tokenizer does not have a padding token by default, the end-of-sentence (EOS) token is explicitly assigned as the padding token. This step ensures uniform sequence lengths during training, crucial for batch processing efficiency.\n",
    "\n",
    "A helper function, `tokenize_batch`, is then defined to streamline tokenization. This function takes batches of textual examples and returns their tokenized versions.\n",
    "\n",
    "Subsequently, the previously filtered training and validation datasets (`train_raw` and `val_raw`) are tokenized using the `.map()` method, which efficiently applies the `tokenize_batch` function to the data in batches. The original \"text\" columns are removed after tokenization, as they are no longer needed once numerical token IDs are created.\n",
    "\n",
    "The resulting datasets, `train_tok` and `val_tok`, are now tokenized and ready for training. Tokenization is essential as it converts human-readable text into numerical format, enabling the model to learn meaningful patterns and relationships in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b424834e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a2f046cd4f424693d50e53e21a5279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d09d669e0a45ccb88bac8bcf99af9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "block_size = 128\n",
    "\n",
    "def group_texts(examples):\n",
    "    # concatenate all tokens then split into blocks\n",
    "    concatenated = sum(examples[\"input_ids\"], [])\n",
    "    total_length = len(concatenated)\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    blocks = [\n",
    "        concatenated[i : i + block_size]\n",
    "        for i in range(0, total_length, block_size)\n",
    "    ]\n",
    "    return {\"input_ids\": blocks, \"attention_mask\": [[1]*block_size]*len(blocks)}\n",
    "\n",
    "train_blocks = train_tok.map(group_texts, batched=True, remove_columns=[\"input_ids\",\"attention_mask\"])\n",
    "val_blocks   = val_tok.map(group_texts, batched=True, remove_columns=[\"input_ids\",\"attention_mask\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7652f",
   "metadata": {},
   "source": [
    "## Explanation of the Code – Grouping Tokenized Text into Fixed-Size Blocks\n",
    "\n",
    "This snippet illustrates the critical step of grouping tokenized textual data into fixed-length blocks, preparing it effectively for language model training. In many transformer-based language modeling tasks, such as training GPT-like models, input sequences must have a consistent length (referred to as `block_size`) to enable batch processing.\n",
    "\n",
    "A predefined block size (in this case, 128 tokens) is set, specifying the exact length of each sequence fed into the model. The function `group_texts` concatenates tokenized inputs from multiple examples into a single continuous list. After concatenation, this long sequence of tokens is segmented into equal-length blocks, ensuring each block matches the predetermined size of 128 tokens.\n",
    "\n",
    "To maintain consistent input shapes, an `attention_mask` is also created, filled entirely with ones (`1`), signifying that all tokens in these blocks are meaningful and should be attended to during model training.\n",
    "\n",
    "Finally, the datasets `train_tok` and `val_tok`, previously tokenized, are transformed using the `.map()` function to generate `train_blocks` and `val_blocks`. These resulting datasets consist of uniform-length sequences, ready for efficient training in batches, optimizing the training speed and stability of the language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3244596",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53c81c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Baseline Perplexity: 81.45\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"baseline_eval\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    eval_dataset=val_blocks,\n",
    ")\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "baseline_loss = eval_results[\"eval_loss\"]\n",
    "baseline_ppl = math.exp(baseline_loss)\n",
    "print(f\"▶️ Baseline Perplexity: {baseline_ppl:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f947ea1",
   "metadata": {},
   "source": [
    "## Explanation of the Code – Evaluating the Pre-trained Language Model (Baseline)\n",
    "\n",
    "This snippet demonstrates how to evaluate a pre-trained causal language model (**DistilGPT-2**) using Hugging Face’s Transformers library. Evaluation helps establish a baseline metric—in this case, perplexity—before any fine-tuning occurs, providing a reference to measure future improvements.\n",
    "\n",
    "Initially, the pre-trained model \"distilgpt2\" is loaded using `AutoModelForCausalLM`. This model, a distilled and smaller variant of GPT-2, is efficient for quick experimentation.\n",
    "\n",
    "A `DataCollatorForLanguageModeling` object is defined, which handles batching the data by appropriately padding token sequences. Here, masked language modeling (`mlm`) is set to `False`, as DistilGPT-2 is trained with causal language modeling.\n",
    "\n",
    "The `TrainingArguments` object specifies evaluation configurations, including:\n",
    "- An output directory (`baseline_eval`) to store evaluation results.\n",
    "- Batch size (`per_device_eval_batch_size=8`) determining how many samples to evaluate at once.\n",
    "- Evaluation mode activated with `do_eval=True` and training explicitly disabled with `do_train=False`.\n",
    "\n",
    "Using these settings, a Hugging Face `Trainer` object is instantiated, connecting the pre-trained model, data collator, and evaluation dataset (`val_blocks`) prepared previously.\n",
    "\n",
    "The `.evaluate()` method computes the evaluation loss, subsequently converted into a standard metric called perplexity (`baseline_ppl`). Perplexity measures how well a model predicts unseen data, with lower values indicating better predictive quality.\n",
    "\n",
    "Thus, the calculated perplexity serves as a critical baseline for assessing subsequent fine-tuning or training efforts, quantifying model performance improvements effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18dd2dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 16:07, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.394000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.472500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.498400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.538600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.561800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.639000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.597100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.338400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.363800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.330400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.335000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.285900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.299200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.185700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.080900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.104500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.134200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>3.183700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>3.154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>3.116900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.988900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>3.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>3.029900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>3.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>3.038800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.973100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.987800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.967100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.924900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.937300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.932200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.938500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.853100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.917400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1960, training_loss=3.18502818029754, metrics={'train_runtime': 968.4009, 'train_samples_per_second': 8.085, 'train_steps_per_second': 2.024, 'total_flos': 255744194641920.0, 'train_loss': 3.18502818029754, 'epoch': 5.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Fine‑tuning (no in‑training evaluation flags)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 2. Fine‑tuning with GPU & FP16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilgpt2-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    logging_steps=50,\n",
    "    fp16=True,           # enable mixed‑precision on GPU\n",
    "    no_cuda=False,       # ensure GPU is used when available\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_blocks,\n",
    "    eval_dataset=val_blocks,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a85106",
   "metadata": {},
   "source": [
    "## Explanation of the Code – Fine-tuning the Language Model with GPU and Mixed-Precision Training\n",
    "\n",
    "This code snippet demonstrates fine-tuning a pre-trained DistilGPT-2 model using Hugging Face’s Transformers library. Fine-tuning adjusts a pre-trained model on a specific dataset, improving its performance for targeted tasks or datasets.\n",
    "\n",
    "Firstly, the code checks for GPU availability (`torch.cuda.is_available()`) and moves the model onto the GPU if present. Utilizing GPU hardware significantly speeds up training compared to CPU usage.\n",
    "\n",
    "The `TrainingArguments` class specifies essential training configurations, including:\n",
    "\n",
    "- **output_dir**: Directory (\"distilgpt2-finetuned\") where model checkpoints and outputs are stored.\n",
    "- **overwrite_output_dir=True**: Allows overwriting previous outputs in the specified directory, useful during iterative experimentation.\n",
    "- **num_train_epochs=5**: Sets the number of epochs (complete passes through the dataset) the model will train, balancing training duration with model performance.\n",
    "- **per_device_train_batch_size=4**: Defines the batch size per device (GPU), determining the number of training samples processed simultaneously.\n",
    "- **logging_steps=50**: Logs training progress after every 50 steps, providing regular performance updates.\n",
    "- **fp16=True**: Activates mixed-precision training (half-precision floating point, FP16) on GPUs, greatly reducing memory usage and training time while maintaining accuracy.\n",
    "- **no_cuda=False**: Explicitly confirms the use of GPU resources when available.\n",
    "\n",
    "The Hugging Face `Trainer` then integrates the pre-trained model, training arguments, training dataset (`train_blocks`), evaluation dataset (`val_blocks`), and data collator. Finally, invoking `trainer.train()` initiates the fine-tuning process, adjusting model parameters based on the provided dataset.\n",
    "\n",
    "By leveraging GPU resources and FP16 optimization, this configuration efficiently enhances model performance, reducing computational requirements and accelerating training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfb43c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fine‑Tuned Perplexity: 49.27\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "finetuned_loss = eval_results[\"eval_loss\"]\n",
    "finetuned_ppl = math.exp(finetuned_loss)\n",
    "print(f\"✅ Fine‑Tuned Perplexity: {finetuned_ppl:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af55a9f8",
   "metadata": {},
   "source": [
    "## Explanation of the Code – Evaluating the Fine-Tuned Language Model\n",
    "\n",
    "This snippet evaluates the performance of the fine-tuned DistilGPT-2 language model by calculating its perplexity on a validation dataset. Perplexity is a widely-used metric in language modeling, reflecting how confidently the model predicts unseen textual data. Lower perplexity values indicate better model performance.\n",
    "\n",
    "After fine-tuning, the model undergoes evaluation using the Hugging Face `Trainer` class’s built-in `.evaluate()` method. This method computes the evaluation loss on the validation dataset (`val_blocks`), representing the model's prediction error.\n",
    "\n",
    "The evaluation loss (`finetuned_loss`) is then converted to perplexity (`finetuned_ppl`) using the mathematical exponential function (`math.exp`). This transformation makes the metric easier to interpret: a lower perplexity implies the model is better at generating coherent text based on context.\n",
    "\n",
    "The resulting perplexity—here reported as **49.27**—reflects a clear improvement over the baseline, highlighting the effectiveness of fine-tuning. Such evaluation results provide concrete evidence of the training procedure’s success, confirming the model's enhanced capability to understand and predict language patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "863bbe59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "perplexities = [81.45, 49.27]\n",
    "labels = [\"Baseline\", \"Fine‑tuned\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(labels, perplexities, edgecolor='black')\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.title(\"Perplexity Before vs. After Fine‑tuning\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29531e90",
   "metadata": {},
   "source": [
    "\n",
    "## Overview\n",
    "\n",
    "This bar chart visualizes the change in **perplexity** of a DistilGPT2 model before and after fine‑tuning on a small WikiText‑2 subset:\n",
    "\n",
    "- **Baseline (pre‑training)**: Perplexity ≈ 81.45  \n",
    "- **Fine‑tuned**: Perplexity ≈ 49.27  \n",
    "\n",
    "_Perplexity_ is a measure of how well a language model predicts a sample. Lower perplexity indicates better predictive performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "1. **Drop in Perplexity**  \n",
    "   The fine‑tuned model’s perplexity (49.27) is substantially lower than the baseline (81.45). This ~40% reduction shows the model has learned the domain‑specific patterns in the WikiText subset.\n",
    "\n",
    "2. **Model Confidence**  \n",
    "   A lower perplexity means the model assigns higher probabilities to the actual next tokens in the validation set—it is less “surprised” by the text.\n",
    "\n",
    "3. **Fine‑Tuning Effectiveness**  \n",
    "   Even with just one epoch of training on a small dataset, fine‑tuning yields a meaningful improvement in language modeling performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This comparison confirms that fine‑tuning on in‑domain data can greatly enhance a pretrained LLM’s fit to the target distribution. To further improve performance, one might:\n",
    "\n",
    "- Experiment with additional epochs and learning‑rate schedules  \n",
    "- Increase training data size  \n",
    "- Perform more extensive hyperparameter tuning  \n",
    "\n",
    "Overall, the chart clearly demonstrates the value of fine‑tuning for domain adaptation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
